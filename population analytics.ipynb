{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bb0fc93-7751-4650-a389-f8b56e97cf0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### analyse de Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38fe7574-d86c-45fa-99ff-f01614b54042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, count, mean, stddev, sum as spark_sum, min as spark_min, max as spark_max,\n",
    "    hour, dayofweek, dayofmonth, month, year, weekofyear,\n",
    "    unix_timestamp, percentile_approx, when, lit\n",
    ")\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Imports Python scientifique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import t, norm\n",
    "\n",
    "# Imports visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Configuration visualisation\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Configuration et imports termin√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c03875-64ae-48cb-a400-b11c8176ef76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType, LongType\n",
    "\n",
    "# CHEMINS DES DONN√âES\n",
    "PATH_POPULATION = \"/Volumes/workspace/trips/population/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5803a044-79fe-4688-a376-74692ebbcb95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üìÇ Chargement des Donn√©es ‚Äì Population (Big Data)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# CHEMIN DES DONN√âES\n",
    "PATH_POPULATION = \"/Volumes/workspace/trips/population/\"\n",
    "\n",
    "# ============================================\n",
    "# CHARGEMENT POPULATION - Approche fichier par fichier\n",
    "# ============================================\n",
    "print(\"üîÑ Chargement de la population compl√®te...\")\n",
    "\n",
    "# Lister tous les fichiers parquet\n",
    "files = [f.path for f in dbutils.fs.ls(PATH_POPULATION) if f.path.endswith(\".parquet\")]\n",
    "print(f\"üìÇ {len(files)} fichiers trouv√©s\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, file_path in enumerate(files, 1):\n",
    "    try:\n",
    "        df_temp = spark.read.parquet(file_path)\n",
    "\n",
    "        columns_to_convert = [\n",
    "            \"passenger_count\", \"trip_distance\", \"RatecodeID\",\n",
    "            \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n",
    "            \"tolls_amount\", \"improvement_surcharge\", \"total_amount\",\n",
    "            \"congestion_surcharge\", \"airport_fee\"\n",
    "        ]\n",
    "\n",
    "        for col_name in columns_to_convert:\n",
    "            if col_name in df_temp.columns:\n",
    "                df_temp = df_temp.withColumn(\n",
    "                    col_name, col(col_name).cast(DoubleType())\n",
    "                )\n",
    "\n",
    "        dfs.append(df_temp)\n",
    "        print(f\"‚úÖ [{i}/{len(files)}] {file_path.split('/')[-1]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur sur {file_path.split('/')[-1]} : {str(e)}\")\n",
    "\n",
    "# Fusion des fichiers\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "print(\"\\nüîÑ Fusion de tous les fichiers parquet...\")\n",
    "df_population = reduce(\n",
    "    lambda df1, df2: df1.unionByName(df2, allowMissingColumns=True),\n",
    "    dfs\n",
    ")\n",
    "\n",
    "nb_population = df_population.count()\n",
    "print(f\"‚úÖ Population totale charg√©e : {nb_population:,} courses\")\n",
    "\n",
    "# V√©rification du sch√©ma final\n",
    "print(\"\\n=== SCH√âMA POPULATION ===\")\n",
    "df_population.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d73efcc-cbfa-4180-b66a-39ad5d567174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== SCH√âMA POPULATION ===\")\n",
    "df_population.printSchema()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7cc2afd-d4b6-4471-aaa0-a28f14ffcaad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== STATISTIQUES DESCRIPTIVES - POPULATION ===\")\n",
    "df_population.select(\n",
    "    \"fare_amount\", \"trip_distance\", \"tip_amount\", \n",
    "    \"tolls_amount\", \"total_amount\", \"passenger_count\"\n",
    ").summary(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e5534b-82b0-45cf-b0d8-64e009432a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "def count_nulls_bigdata(df, dataset_name):\n",
    "    print(f\"\\n=== VALEURS MANQUANTES - {dataset_name} ===\")\n",
    "    total_rows = df.count()\n",
    "    null_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "    null_counts.show(truncate=False)\n",
    "    # Pourcentage\n",
    "    null_pct = null_counts.select([(col(c)/total_rows*100).alias(c+\"_pct\") for c in null_counts.columns])\n",
    "    null_pct.show(truncate=False)\n",
    "\n",
    "count_nulls_bigdata(df_population, \"POPULATION\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30246b9c-8617-46d7-9d65-7418f895f28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62828a9b-06f6-4fe7-b191-c9cd6356e7c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51c5d38b-f182-42af-b6f6-3ede568c3f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Pour chaque colonne, compter les valeurs nulles\n",
    "df_population.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef096c29-9a77-42a0-bfc3-29aea42af664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6d2a135-a9f6-4540-b027-add4f0b00472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### description des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee518fe5-b3ba-4e30-8c0b-14450bcc9a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population.select(\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"total_amount\",\n",
    "    \"tip_amount\",\n",
    "    \"passenger_count\"\n",
    ").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5368dc6-e17f-4592-a1a9-6b30e27efdce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# payment_type\n",
    "df_population.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd73826-1d1b-4fd4-a302-db5cb0e6a0c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# RatecodeID : Type de tarif appliqu√©\n",
    "df_population.groupBy(\"RatecodeID\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96fa0cad-d568-453a-b6fb-4009fc11dccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### les valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b4e2d0-75a0-4b76-beaf-0c42bb202143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population = df_population.withColumn(\n",
    "    \"airport_fee\",\n",
    "    when(\n",
    "        col(\"airport_fee\").isNull() &\n",
    "        (~col(\"PULocationID\").isin([132, 138])),\n",
    "        lit(0)\n",
    "    ).otherwise(col(\"airport_fee\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7040b55-7948-413c-8f02-5f050b9101e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# √âtape 1: m√©diane par zone\n",
    "median_passenger_by_zone = (\n",
    "    df_population\n",
    "    .groupBy(\"PULocationID\")\n",
    "    .agg({\"passenger_count\": \"median\"})\n",
    "    .withColumnRenamed(\"median(passenger_count)\", \"median_passenger\")\n",
    ")\n",
    "\n",
    "# √âtape 2: jointure + imputation\n",
    "df_population = (\n",
    "    df_population\n",
    "    .join(median_passenger_by_zone, on=\"PULocationID\", how=\"left\")\n",
    "    .withColumn(\n",
    "        \"passenger_count\",\n",
    "        when(\n",
    "            col(\"passenger_count\").isNull(),\n",
    "            col(\"median_passenger\")\n",
    "        ).otherwise(col(\"passenger_count\"))\n",
    "    )\n",
    "    .drop(\"median_passenger\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8966914d-b2a4-48e8-a951-b7f29204be20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# √âtape 1: calcul du mode par zone\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "w = Window.partitionBy(\"PULocationID\").orderBy(col(\"count\").desc())\n",
    "\n",
    "ratecode_mode = (\n",
    "    df_population\n",
    "    .groupBy(\"PULocationID\", \"RatecodeID\")\n",
    "    .count()\n",
    "    .withColumn(\"rn\", row_number().over(w))\n",
    "    .filter(col(\"rn\") == 1)\n",
    "    .select(\"PULocationID\", col(\"RatecodeID\").alias(\"mode_ratecode\"))\n",
    ")\n",
    "\n",
    "# √âtape 2: jointure + imputation\n",
    "df_population = (\n",
    "    df_population\n",
    "    .join(ratecode_mode, on=\"PULocationID\", how=\"left\")\n",
    "    .withColumn(\n",
    "        \"RatecodeID\",\n",
    "        when(\n",
    "            col(\"RatecodeID\").isNull(),\n",
    "            col(\"mode_ratecode\")\n",
    "        ).otherwise(col(\"RatecodeID\"))\n",
    "    )\n",
    "    .drop(\"mode_ratecode\")\n",
    ")\n",
    "# s‚Äôil reste encore des null ‚Üí valeur par d√©faut = 1\n",
    "df_population = df_population.fillna({\"RatecodeID\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea8d51a3-c54f-4243-8804-76219269cdfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population = df_population.fillna({\"store_and_fwd_flag\": \"N\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4afc788-631c-4ad5-8f57-92c7cee41a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "money_cols = [\"congestion_surcharge\", \"airport_fee\"]\n",
    "\n",
    "df_population = df_population.fillna(\n",
    "    {c: 0 for c in money_cols}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e617169f-d9a2-4745-ac83-0964e4a80d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_population.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in df_population.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "429af38a-7eda-4941-b9db-a13c44a04c5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### statistiques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a236d88-87a2-4502-94e1-142179e9021a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcul des quartiles pour fare_amount\n",
    "quantiles_fare = df_population.approxQuantile(\"fare_amount\", [0.01, 0.25, 0.50, 0.75, 0.99], 0.01)\n",
    "Q1, Q3 = quantiles_fare[1], quantiles_fare[3]\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"=== ANALYSE FARE_AMOUNT ===\")\n",
    "print(f\"Q1 (25%): ${Q1:.2f}\")\n",
    "print(f\"M√©diane (50%): ${quantiles_fare[2]:.2f}\")\n",
    "print(f\"Q3 (75%): ${Q3:.2f}\")\n",
    "print(f\"IQR: ${IQR:.2f}\")\n",
    "print(f\"1er percentile: ${quantiles_fare[0]:.2f}\")\n",
    "print(f\"99e percentile: ${quantiles_fare[4]:.2f}\")\n",
    "\n",
    "# Limites outliers (m√©thode IQR)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(f\"\\nLimites outliers (IQR ¬±1.5):\")\n",
    "print(f\"Limite inf√©rieure: ${lower_bound:.2f}\")\n",
    "print(f\"Limite sup√©rieure: ${upper_bound:.2f}\")\n",
    "\n",
    "# Comptage outliers\n",
    "nb_outliers = df_population.filter(\n",
    "    (col(\"fare_amount\") < lower_bound) | (col(\"fare_amount\") > upper_bound)\n",
    ").count()\n",
    "pct_outliers = (nb_outliers / nb_population) * 100\n",
    "\n",
    "print(f\"\\nüìä Outliers d√©tect√©s: {nb_outliers:,} ({pct_outliers:.2f}%)\")\n",
    "\n",
    "# COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec005f38-a6da-4de4-8ff1-b1338d9bb566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### prix moyenne dune course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0154ae32-f67f-45d4-9606-c177e3ae8176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mean_population = df_population.agg({\"fare_amount\": \"mean\"}).first()[0]\n",
    "mean_population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4baa76b0-f253-450a-b15b-97a6f0083cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distance moyenne (trip_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6705f16b-fb1f-4f7a-b839-b21442640139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mean_dist_pop = df_population.agg({\"trip_distance\": \"mean\"}).first()[0]\n",
    "mean_dist_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07559db9-c697-45d2-ad0f-f3e2caa2a882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dur√©e moyenne des courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6794a822-67c3-4a37-9f22-a8c07ae9c7ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mean_trip_duration_min=df_population.agg({\"trip_duration_min\": \"mean\"}).first()[0]\n",
    "mean_trip_duration_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba065c09-62f4-4b11-88de-0cb710abeaac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Proportion des courses avec tip > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1a00a0-ddc1-4975-96e6-5299f5deb71f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prop_pop = df_population.filter(col(\"tip_amount\") > 0).count() / df_clean.count()\n",
    "prop_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2ce74e7-fcf4-4944-b65e-3d75ff471fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distribution par heure / jour / semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38e8d42-2100-4f1f-9fde-d66fdf9dd814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek\n",
    "\n",
    "df_population = df_population.withColumn(\"hour\", hour(\"tpep_pickup_datetime\"))\n",
    "df_population = df_population.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "\n",
    "nbr_trips_per_hour=df_clean.groupBy(\"hour\").count()\n",
    "nbr_trips_per_hour.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c30b0c03-7d76-486d-8433-714f69061de1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fares_pickup_borough=df_population.groupBy(\"PULocationID\").agg(\n",
    "    {\"fare_amount\": \"mean\"}\n",
    ")\n",
    "fares_pickup_borough.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d1d110e-f341-4444-9007-851a83a23138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_population.select(\"fare_amount\") \\\n",
    "        .filter(col(\"fare_amount\") == 0) \\\n",
    "        .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "population analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
